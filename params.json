{"name":"Semeval2016-task6","tagline":"SemEval2016 Task 6: Detecting Stance in Tweets","body":"### Stance Detection in Tweets: Yes or No?\r\nThis is the project page for [SemEval 2016 task 6](http://alt.qcri.org/semeval2016/task6/): Detecting Stance in Tweets.\r\n\r\n### DATA and Task:\r\n* A topic, a piece of text, mentions and hashtags are given. The question is whether the tweet is in favour, against or neutral about the topic.\r\n* The distribution of labels is shown [here](https://drive.google.com/open?id=0B9ZfPKPvp-JiLUhqTE5jTXR2X3M). The AGAINST tweets are twice the number of FAVOR or NONE (neutral) tweets.\r\n\r\n* The distribution of topics is shown [here](https://drive.google.com/open?id=0B9ZfPKPvp-JiUURZbjhpNTRaNkU). The distribution of tweets among topics seems to be almost uniform.\r\n* The number of training and development samples are 2815 and 100 respectively.\r\n\r\n### Models\r\n* Baseline 1: Train a text-based classifier over all training samples regardless of their topic and test it on development data. The cost function is hinge loss (SVM) and Elastic Net (50% l1 and 50% l2) regularisation. 10-fold cross validation has been used for tuning the regularisation coefficient.\r\n\r\n`\r\n\r\n    _        precision    recall  f1-score   support\r\n\r\n    AGAINST      0.68     0.85     0.76       53     \r\n\r\n       AVOR      0.70     0.64     0.67       22     \r\n\r\n       NONE      0.71     0.40     0.51       25     \r\n\r\n        avg      0.69     0.69     0.68      100     \r\n\r\n`\r\n\r\n\r\n\r\n### Evaluation\r\n* Task is evaluated with the average of f-scores for FAVOR and AGAINST labels.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}